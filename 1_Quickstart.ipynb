{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyONaL06PfIXL4glX5Syhxxs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohammadreza-mohammadi94/Agentic-AI-LLM-Apps/blob/main/1_Quickstart.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')\n"
      ],
      "metadata": {
        "id": "ONwrtenZwFzU"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Quickstart"
      ],
      "metadata": {
        "id": "SOKPZ8eaySRm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tivy1vnXsp2B",
        "outputId": "a63422a3-39f8-4758-ba1f-fe39198a6d8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Under a sky full of twinkling stars, a gentle unicorn whispered magical dreams to sleepy children as they drifted off to sleep.\n"
          ]
        }
      ],
      "source": [
        "# Example\n",
        "\n",
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "  model=\"gpt-4.1-mini\",\n",
        "  messages=[{\"role\": \"user\", \"content\": \"Write a one-sentence bedtime story about a unicorn.\"}])\n",
        "\n",
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extend the model with tools"
      ],
      "metadata": {
        "id": "kKn1i4ShxFKl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "\n",
        "response = client.responses.create(\n",
        "    model=\"gpt-4.1-mini\",\n",
        "    tools=[{'type': 'web_search'}],\n",
        "    input=\"What was a positive news story from today?\"\n",
        ")\n",
        "\n",
        "print(response.output_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kq4rYM0ht-de",
        "outputId": "2d17ed7f-482b-4dec-b66e-663b44e0918f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On September 23, 2025, several positive developments were reported:\n",
            "\n",
            "**1. New Mexico's Universal Childcare Initiative**\n",
            "\n",
            "New Mexico has taken a groundbreaking step by eliminating income eligibility requirements for its childcare assistance program. Starting in November, families of all income levels will have access to childcare without meeting prior income thresholds. This initiative aims to ease financial burdens and expand early education opportunities statewide. ([info.thatsgreatnews.com](https://info.thatsgreatnews.com/from-green-innovation-to-community-triumphs-uplifting-us-stories-lighting-up-september-2025/?utm_source=openai))\n",
            "\n",
            "**2. Advances in Marine Conservation**\n",
            "\n",
            "Scientists have developed a new chemical procedure that transforms plastic waste, such as single-use carrier bags and food containers, back into materials usable for producing new plastics. This process targets polyethylene and polypropylene, which constitute about two-thirds of consumer plastic waste worldwide. By converting plastic waste into recyclable components, the method reduces the need for virgin plastic production and the associated fossil fuel consumption. ([mcsuk.org](https://www.mcsuk.org/news/positive-ocean-news-september-24/?utm_source=openai))\n",
            "\n",
            "**3. Record Solar Energy Expansion**\n",
            "\n",
            "In the first half of 2025, the world added 380 gigawatts (GW) of new solar capacity, marking a 64% increase from the same period in 2024. This surge in solar energy adoption signifies a global shift towards renewable energy sources and a commitment to reducing carbon emissions. ([onlygoodnewsdaily.com](https://www.onlygoodnewsdaily.com/post/good-news-worth-celebrating-13-sept-2025?utm_source=openai))\n",
            "\n",
            "These stories highlight significant strides in environmental conservation, renewable energy adoption, and social welfare initiatives, reflecting a positive trajectory in addressing global challenges. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "191d8172"
      },
      "source": [
        "Here's the clarification on the difference between `client.chat.completions.create` and `client.responses.create` based on the current OpenAI Python library:\n",
        "\n",
        "*   **`client.chat.completions.create`**: This is the **standard and current** way to interact with the chat models (like `gpt-4.1-mini`) in the latest versions of the OpenAI Python library. This method is designed for conversational interactions and supports features like providing a history of messages, using tools, and specifying roles (user, assistant, system).\n",
        "\n",
        "*   **`client.responses.create`**: This method is **not a standard part** of the current OpenAI Python library for creating chat completions or general text responses. It's possible this was part of an older version of the library, a different library, or a custom implementation. Attempting to use this method with the current library version will likely result in an `AttributeError`.\n",
        "\n",
        "In summary, you should use `client.chat.completions.create` for generating text and interacting with the chat models, including when using tools."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q76RCNPwycdZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stream responses and build realtime apps\n"
      ],
      "metadata": {
        "id": "9ZJeit8zyrwh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -q openai-agents"
      ],
      "metadata": {
        "id": "SlFNxk1D3DQu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3211cfd5"
      },
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "\n",
        "stream = client.responses.create(\n",
        "    model=\"gpt-4.1-mini\",\n",
        "    input=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Say 'double bubble bath' ten times fast.\",\n",
        "        },\n",
        "    ],\n",
        "    stream=True,\n",
        ")\n",
        "\n",
        "# for event in stream:\n",
        "#     print(event)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oOHFspPMycad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build Agents"
      ],
      "metadata": {
        "id": "z7CfNItI2kjn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from agents import Agent, Runner\n",
        "import asyncio\n",
        "\n",
        "# Spanish\n",
        "spanish_agent = Agent(\n",
        "    name=\"Spanish_Agent\",\n",
        "    instructions=\"You only speak Spanish.\",\n",
        ")\n",
        "\n",
        "# English\n",
        "english_agent = Agent(\n",
        "    name=\"English_Agent\",\n",
        "    instructions=\"You only speak English.\",\n",
        ")\n",
        "\n",
        "triage_agent = Agent(\n",
        "    name=\"Triage agent\",\n",
        "    instructions=\"Handoff to the appropriate agent based on the language of the request.\",\n",
        "    handoffs=[spanish_agent, english_agent],\n",
        ")\n",
        "\n",
        "\n",
        "async def main():\n",
        "    result = await Runner.run(triage_agent, input=\"Hola, ¿cómo estás?\")\n",
        "    print(result.final_output)\n",
        "\n",
        "\n",
        "await main()"
      ],
      "metadata": {
        "id": "yG6GASfLycXh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}